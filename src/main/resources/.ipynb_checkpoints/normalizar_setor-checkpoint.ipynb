{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "960776f5-5966-42ef-9abf-7d5c1b466711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'C:\\Users\\MENICIO JR\\Desktop\\Natural2SPARQL-master\\src\\main\\resources\\setor_map.json' lido com sucesso.\n",
      "Dados (chaves e valores) normalizados.\n",
      "Arquivo totalmente normalizado salvo em 'C:\\Users\\MENICIO JR\\Desktop\\Natural2SPARQL-master\\src\\main\\resources\\setor_map_totalmente_normalizado.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "import string\n",
    "import os\n",
    "\n",
    "def remover_acentos(texto: str) -> str:\n",
    "    \"\"\"Remove acentos de uma string.\"\"\"\n",
    "    nfkd_form = unicodedata.normalize('NFKD', texto)\n",
    "    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def remover_pontuacao(texto: str) -> str:\n",
    "    \"\"\"Remove pontuação de uma string.\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return texto.translate(translator)\n",
    "\n",
    "def normalizar_texto(texto: str) -> str:\n",
    "    \"\"\"Normaliza um texto: minúsculas, sem acentos, sem pontuação e remove espaços extras.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return texto\n",
    "\n",
    "    texto = texto.lower()\n",
    "    texto = remover_acentos(texto)\n",
    "    texto = remover_pontuacao(texto)\n",
    "    texto = \" \".join(texto.split())\n",
    "    return texto\n",
    "\n",
    "def normalizar_estrutura_json(data):\n",
    "    \"\"\"\n",
    "    Navega recursivamente pela estrutura JSON (dicionários e listas)\n",
    "    e aplica a normalização de texto a todas as chaves de string e valores de string.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        novo_dict = {}\n",
    "        for k, v in data.items():\n",
    "            chave_normalizada = k # Por padrão, assume que a chave pode não ser string\n",
    "            if isinstance(k, str):\n",
    "                chave_normalizada = normalizar_texto(k)\n",
    "            \n",
    "            valor_normalizado = normalizar_estrutura_json(v)\n",
    "            \n",
    "            # Se a chave normalizada já existe e o valor é diferente,\n",
    "            # você pode querer uma estratégia de mesclagem ou aviso.\n",
    "            # Por simplicidade, a última entrada com a mesma chave normalizada prevalecerá.\n",
    "            if chave_normalizada in novo_dict and novo_dict[chave_normalizada] != valor_normalizado:\n",
    "                print(f\"Aviso: Chave normalizada duplicada '{chave_normalizada}' encontrada. \"\n",
    "                      f\"Valor antigo: '{novo_dict[chave_normalizada]}', \"\n",
    "                      f\"Novo valor: '{valor_normalizado}'. O novo valor prevalecerá.\")\n",
    "            novo_dict[chave_normalizada] = valor_normalizado\n",
    "        return novo_dict\n",
    "    elif isinstance(data, list):\n",
    "        return [normalizar_estrutura_json(item) for item in data]\n",
    "    elif isinstance(data, str):\n",
    "        return normalizar_texto(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def main():\n",
    "    # Caminho do arquivo de entrada (usando o arquivo que você gerou como exemplo de entrada agora)\n",
    "    # Se quiser rodar no original, mude para setor_map.json\n",
    "    caminho_arquivo_entrada = r\"C:\\Users\\MENICIO JR\\Desktop\\Natural2SPARQL-master\\src\\main\\resources\\setor_map.json\"\n",
    "    # Ou, se você quiser processar o arquivo que já tinha valores normalizados:\n",
    "    # caminho_arquivo_entrada = r\"C:\\Users\\MENICIO JR\\Desktop\\Natural2SPARQL-master\\src\\main\\resources\\setor_map_normalizado.json\"\n",
    "\n",
    "\n",
    "    if not os.path.exists(caminho_arquivo_entrada):\n",
    "        print(f\"Erro: O arquivo de entrada não foi encontrado em '{caminho_arquivo_entrada}'\")\n",
    "        return\n",
    "\n",
    "    diretorio_entrada, nome_arquivo_entrada = os.path.split(caminho_arquivo_entrada)\n",
    "    nome_base, extensao = os.path.splitext(nome_arquivo_entrada)\n",
    "    # Nome do arquivo de saída para evitar sobrescrever o anterior se você rodar múltiplas vezes\n",
    "    caminho_arquivo_saida = os.path.join(diretorio_entrada, f\"{nome_base}_totalmente_normalizado{extensao}\")\n",
    "\n",
    "    try:\n",
    "        with open(caminho_arquivo_entrada, 'r', encoding='utf-8') as f_entrada:\n",
    "            dados_json = json.load(f_entrada)\n",
    "        print(f\"Arquivo '{caminho_arquivo_entrada}' lido com sucesso.\")\n",
    "\n",
    "        dados_normalizados = normalizar_estrutura_json(dados_json)\n",
    "        print(\"Dados (chaves e valores) normalizados.\")\n",
    "\n",
    "        with open(caminho_arquivo_saida, 'w', encoding='utf-8') as f_saida:\n",
    "            json.dump(dados_normalizados, f_saida, ensure_ascii=False, indent=4)\n",
    "        print(f\"Arquivo totalmente normalizado salvo em '{caminho_arquivo_saida}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo não encontrado em '{caminho_arquivo_entrada}'\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Erro: O arquivo '{caminho_arquivo_entrada}' não é um JSON válido.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro inesperado: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa103600-b229-4706-8def-331bae53c196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
